{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Machine Learning (Data Preprocessing Tools)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**                | **Description**                                                                                                                                                       |\n",
    "|---------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Definition**            | Data preprocessing is the process of transforming raw data into a clean and usable format to enhance the performance of machine learning models.                       |\n",
    "| **Importance**            | Ensures data quality, improves model accuracy, reduces computational complexity, and helps in handling missing or inconsistent data.                                    |\n",
    "| **Steps**                 | Key steps involved in data preprocessing include:                                                                                                                      |\n",
    "| **Data Cleaning**         | Removing or fixing missing, duplicate, or incorrect data.                                                                                                              |\n",
    "| **Data Integration**      | Combining data from multiple sources into a coherent dataset.                                                                                                           |\n",
    "| **Data Transformation**   | Scaling, normalizing, or converting data into appropriate formats for analysis.                                                                                         |\n",
    "| **Data Reduction**        | Reducing data volume while maintaining its integrity, often through techniques like dimensionality reduction or feature selection.                                       |\n",
    "| **Data Encoding**         | Converting categorical data into numerical format using methods like one-hot encoding or label encoding.                                                                |\n",
    "| **Data Normalization**    | Scaling data to a standard range, such as 0-1, to ensure uniformity in analysis.                                                                                        |\n",
    "| **Feature Extraction**    | Creating new features from existing data to enhance model performance.                                                                                                 |\n",
    "| **Outlier Detection**     | Identifying and handling data points that deviate significantly from the rest of the dataset.                                                                           |\n",
    "| **Imputation**            | Filling in missing data with appropriate values, such as mean, median, mode, or using algorithms.                                                                       |\n",
    "| **Splitting Data**        | Dividing the dataset into training, validation, and test sets to evaluate model performance accurately.                                                                 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EoRP98MpR-qj"
   },
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N-qiINBQSK2g"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RopL7tUZSQkT"
   },
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwEPNDWySTKm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./data/sale.csv')\n",
    "dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, nan],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', nan, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:, :-1].values # this code select all columns except the last one\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     No\n",
       "1    Yes\n",
       "2     No\n",
       "3     No\n",
       "4    Yes\n",
       "5    Yes\n",
       "6     No\n",
       "7    Yes\n",
       "8     No\n",
       "9    Yes\n",
       "Name: Purchased, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=dataset.iloc[:,-1] # this code select the last one only\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nhfKXNxlSabC"
   },
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**               | **Description**                                                                                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Tool**                 | SimpleImputer                                                                                                                                                           |\n",
    "| **Library**              | Scikit-learn                                                                                                                                                            |\n",
    "| **Definition**           | A transformer from Scikit-learn used for imputing missing values in a dataset by applying a specified strategy for each feature (column).                                |\n",
    "| **Primary Use**          | Handling missing data by replacing it with a specified value or a statistical measure such as mean, median, or most frequent value.                                      |\n",
    "| **Imputation Strategies**| - **Mean**: Replaces missing values using the mean along each column.                                                                                                   |\n",
    "|                          | - **Median**: Replaces missing values using the median along each column.                                                                                               |\n",
    "|                          | - **Most Frequent**: Replaces missing values using the most frequent value along each column.                                                                            |\n",
    "|                          | - **Constant**: Replaces missing values with a constant value defined by the user.                                                                                       |\n",
    "| **Parameters**           | - `missing_values`: The placeholder for missing values (e.g., `np.nan`).                                                                                                |\n",
    "|                          | - `strategy`: The imputation strategy to use (`mean`, `median`, `most_frequent`, `constant`).                                                                            |\n",
    "|                          | - `fill_value`: When strategy is `constant`, this is the value used to replace missing values.                                                                            |\n",
    "| **Attributes**           | - `statistics_`: The statistics computed during fitting that are used for imputation.                                                                                    |\n",
    "| **Methods**              | - `fit(X)`: Computes the statistics for imputation from the dataset `X`.                                                                                                 |\n",
    "|                          | - `transform(X)`: Imputes the missing values in the dataset `X` using the computed statistics.                                                                           |\n",
    "|                          | - `fit_transform(X)`: Fits to the data `X` and then transforms it.                                                                                                       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c93k7ipkSexq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['France', 44.0, 72000.0],\n",
       "       ['Spain', 27.0, 48000.0],\n",
       "       ['Germany', 30.0, 54000.0],\n",
       "       ['Spain', 38.0, 61000.0],\n",
       "       ['Germany', 40.0, 63777.77777777778],\n",
       "       ['France', 35.0, 58000.0],\n",
       "       ['Spain', 38.77777777777778, 52000.0],\n",
       "       ['France', 48.0, 79000.0],\n",
       "       ['Germany', 50.0, 83000.0],\n",
       "       ['France', 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CriG6VzVSjcK"
   },
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AhSpdQWeSsFh"
   },
   "source": [
    "### Encoding the Independent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**               | **Description**                                                                                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Tool**                 | ColumnTransformer                                                                                                                                                       |\n",
    "| **Library**              | Scikit-learn                                                                                                                                                            |\n",
    "| **Definition**           | A transformer that applies different preprocessing steps to different subsets of features in a dataset.                                                                 |\n",
    "| **Primary Use**          | Facilitates the application of distinct data transformations to different columns within a single pipeline.                                                             |\n",
    "| **Parameters**           | - `transformers`: List of (name, transformer, columns) tuples specifying the transformers to be applied and the columns they apply to.                                    |\n",
    "|                          | - `remainder`: Specifies what to do with remaining columns that are not explicitly specified in the `transformers` list. Options include 'drop', 'passthrough', or a transformer. |\n",
    "|                          | - `n_jobs`: Number of jobs to run in parallel.                                                                                                                           |\n",
    "| **Attributes**           | - `transformers_`: The collection of fitted transformers as tuples of (name, fitted_transformer, column).                                                                |\n",
    "|                          | - `named_transformers_`: Access fitted transformer by name.                                                                                                              |\n",
    "|                          | - `remainder_`: Transformer used for remaining columns.                                                                                                                  |\n",
    "| **Methods**              | - `fit(X)`: Fits all transformers using the data `X`.                                                                                                                    |\n",
    "|                          | - `transform(X)`: Applies transformations to the data `X` and concatenates the results.                                                                                   |\n",
    "|                          | - `fit_transform(X)`: Fits all transformers and applies them to the data `X`.                                                                                            |\n",
    "|                          | - `inverse_transform(X)`: Reverts the transformations back to the original space.                                                                                        |\n",
    "| **Example Usage**        | ```python                                                                                                                                                               |\n",
    "|                          | from sklearn.compose import ColumnTransformer                                                                                                                           |\n",
    "|                          | from sklearn.preprocessing import StandardScaler, OneHotEncoder                                                                                                          |\n",
    "|                          | import pandas as pd                                                                                                                                                     |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | data = pd.DataFrame({                                                                                                                                                   |\n",
    "|                          |     'numerical_feature': [0.5, 0.3, 0.9],                                                                                                                               |\n",
    "|                          |     'categorical_feature': ['A', 'B', 'A']                                                                                                                               |\n",
    "|                          | })                                                                                                                                                                       |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | transformer = ColumnTransformer(                                                                                                                                       |\n",
    "|                          |     transformers=[                                                                                                                                                      |\n",
    "|                          |         ('num', StandardScaler(), ['numerical_feature']),                                                                                                                |\n",
    "|                          |         ('cat', OneHotEncoder(), ['categorical_feature'])                                                                                                                |\n",
    "|                          |     ])                                                                                                                                                                   |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | transformed_data = transformer.fit_transform(data)                                                                                                                       |\n",
    "|                          | ```                                                                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**               | **Description**                                                                                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Tool**                 | OneHotEncoder                                                                                                                                                           |\n",
    "| **Library**              | Scikit-learn                                                                                                                                                            |\n",
    "| **Definition**           | A transformer that converts categorical features into a one-hot numeric array, where each unique category is represented by a binary column.                             |\n",
    "| **Primary Use**          | Encoding categorical variables as a one-hot numeric array for use in machine learning algorithms.                                                                        |\n",
    "| **Parameters**           | - `categories`: Specifies the categories for each feature. `‘auto’` means the categories are determined from the data.                                                   |\n",
    "|                          | - `drop`: Specifies a methodology to drop one of the categories per feature to avoid collinearity.                                                                       |\n",
    "|                          | - `sparse`: If True, returns a sparse matrix. If False, returns a dense array.                                                                                           |\n",
    "|                          | - `dtype`: The desired data-type for the output array.                                                                                                                   |\n",
    "|                          | - `handle_unknown`: Specifies the behavior when an unknown category is encountered. Options are `‘error’` (default) and `‘ignore’`.                                       |\n",
    "| **Attributes**           | - `categories_`: The categories identified for each feature.                                                                                                            |\n",
    "|                          | - `drop_idx_`: The indices of the dropped categories if `drop` is specified.                                                                                             |\n",
    "| **Methods**              | - `fit(X)`: Fits the encoder to the data `X`.                                                                                                                            |\n",
    "|                          | - `transform(X)`: Transforms the data `X` using the fitted encoder.                                                                                                      |\n",
    "|                          | - `fit_transform(X)`: Fits the encoder and transforms the data `X`.                                                                                                       |\n",
    "|                          | - `inverse_transform(X)`: Converts the encoded data back to the original categories.                                                                                      |\n",
    "|                          | - `get_feature_names_out()`: Returns feature names for the output array.                                                                                                |\n",
    "| **Example Usage**        | ```python                                                                                                                                                               |\n",
    "|                          | from sklearn.preprocessing import OneHotEncoder                                                                                                                         |\n",
    "|                          | import numpy as np                                                                                                                                                      |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | data = np.array([['A'], ['B'], ['A'], ['C']])                                                                                                                           |\n",
    "|                          | encoder = OneHotEncoder(sparse=False)                                                                                                                                   |\n",
    "|                          | encoded_data = encoder.fit_transform(data)                                                                                                                               |\n",
    "|                          | print(encoded_data)                                                                                                                                                     |\n",
    "|                          | ```                                                                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5hwuVddlSwVi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0],\n",
       "       [0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DXh8oVSITIc6"
   },
   "source": [
    "### Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LableEncoder\n",
    "| **Aspect**               | **Description**                                                                                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Tool**                 | LabelEncoder                                                                                                                                                            |\n",
    "| **Library**              | Scikit-learn                                                                                                                                                            |\n",
    "| **Definition**           | A transformer that encodes target labels with values between 0 and n_classes-1.                                                                                          |\n",
    "| **Primary Use**          | Converting categorical labels into numeric format for use in machine learning algorithms.                                                                                |\n",
    "| **Parameters**           | None.                                                                                                                                                                   |\n",
    "| **Attributes**           | - `classes_`: The unique classes identified during fitting.                                                                                                             |\n",
    "| **Methods**              | - `fit(y)`: Fits the encoder to the labels `y`.                                                                                                                          |\n",
    "|                          | - `transform(y)`: Transforms the labels `y` to numeric values.                                                                                                           |\n",
    "|                          | - `fit_transform(y)`: Fits the encoder and transforms the labels `y`.                                                                                                     |\n",
    "|                          | - `inverse_transform(y)`: Converts numeric values back to the original labels.                                                                                           |\n",
    "|                          | - `fit_transform(y)`: Fits the encoder and transforms the labels `y` in a single step.                                                                                   |\n",
    "| **Example Usage**        | ```python                                                                                                                                                               |\n",
    "|                          | from sklearn.preprocessing import LabelEncoder                                                                                                                          |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | data = ['cat', 'dog', 'fish', 'dog', 'cat']                                                                                                                             |\n",
    "|                          | encoder = LabelEncoder()                                                                                                                                                |\n",
    "|                          | encoded_data = encoder.fit_transform(data)                                                                                                                              |\n",
    "|                          | print(encoded_data)  # Output: array([0, 1, 2, 1, 0])                                                                                                                   |\n",
    "|                          | print(encoder.classes_)  # Output: array(['cat', 'dog', 'fish'], dtype='<U4')                                                                                           |\n",
    "|                          | decoded_data = encoder.inverse_transform(encoded_data)                                                                                                                  |\n",
    "|                          | print(decoded_data)  # Output: array(['cat', 'dog', 'fish', 'dog', 'cat'], dtype='<U4')                                                                                  |\n",
    "|                          | ```                                                                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XgHCShVyTOYY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qb_vcgm3qZKW"
   },
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**               | **Description**                                                                                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Tool**                 | train_test_split                                                                                                                                                        |\n",
    "| **Library**              | Scikit-learn                                                                                                                                                            |\n",
    "| **Definition**           | A utility function that splits arrays or matrices into random train and test subsets.                                                                                     |\n",
    "| **Primary Use**          | Dividing a dataset into training and testing sets for model evaluation.                                                                                                |\n",
    "| **Parameters**           | - `*arrays`: The input data to be split, such as features and labels.                                                                                                   |\n",
    "|                          | - `test_size`: The proportion of the dataset to include in the test split. Can be a float between 0.0 and 1.0, or an integer for the absolute number of test samples.   |\n",
    "|                          | - `train_size`: The proportion of the dataset to include in the train split. Can be a float between 0.0 and 1.0, or an integer for the absolute number of train samples. |\n",
    "|                          | - `random_state`: Controls the shuffling applied to the data before the split for reproducibility.                                                                      |\n",
    "|                          | - `shuffle`: Whether or not to shuffle the data before splitting. Default is `True`.                                                                                     |\n",
    "|                          | - `stratify`: If not `None`, data is split in a stratified fashion, using this as the class labels.                                                                      |\n",
    "| **Returns**              | - `splits`: A list containing train-test splits of the input data. Typically, four outputs are returned: `X_train`, `X_test`, `y_train`, `y_test`.                                                            |\n",
    "| **Example Usage**        | ```python                                                                                                                                                               |\n",
    "|                          | from sklearn.model_selection import train_test_split                                                                                                                    |\n",
    "|                          | import numpy as np                                                                                                                                                      |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | X = np.arange(10).reshape((5, 2))                                                                                                                                       |\n",
    "|                          | y = np.array([0, 1, 2, 3, 4])                                                                                                                                           |\n",
    "|                          | X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)                                                                               |\n",
    "|                          | print(\"X_train:\", X_train)                                                                                                                                              |\n",
    "|                          | print(\"X_test:\", X_test)                                                                                                                                                |\n",
    "|                          | print(\"y_train:\", y_train)                                                                                                                                              |\n",
    "|                          | print(\"y_test:\", y_test)                                                                                                                                                |\n",
    "|                          | ```                                                                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXgA6CzlqbCl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "GuwQhFdKrYTM",
    "outputId": "de1e527f-c229-4daf-e7c5-ea9d2485148d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 0.0, 1.0, 38.77777777777778, 52000.0],\n",
       "       [0.0, 1.0, 0.0, 40.0, 63777.77777777778],\n",
       "       [1.0, 0.0, 0.0, 44.0, 72000.0],\n",
       "       [0.0, 0.0, 1.0, 38.0, 61000.0],\n",
       "       [0.0, 0.0, 1.0, 27.0, 48000.0],\n",
       "       [1.0, 0.0, 0.0, 48.0, 79000.0],\n",
       "       [0.0, 1.0, 0.0, 50.0, 83000.0],\n",
       "       [1.0, 0.0, 0.0, 35.0, 58000.0]], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TUrX_Tvcrbi4",
    "outputId": "9a041a9b-2642-4828-fa2f-a431d7d77631"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0, 1.0, 0.0, 30.0, 54000.0],\n",
       "       [1.0, 0.0, 0.0, 37.0, 67000.0]], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pSMHiIsWreQY",
    "outputId": "5afe91e0-9244-4bf5-ec1b-e3e092b85c08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I_tW7H56rgtW",
    "outputId": "2a93f141-2a99-4a69-eec5-c82a3bb8d36b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TpGqbS4TqkIR"
   },
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Aspect**               | **Description**                                                                                                                                                         |\n",
    "|--------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **Definition**           | Feature scaling is the process of normalizing or standardizing the range of independent variables or features in a dataset.                                              |\n",
    "| **Primary Use**          | Ensuring that features contribute equally to the model, improving the performance and convergence speed of machine learning algorithms, especially those based on distance calculations.|\n",
    "| **Common Methods**       | - **Normalization (Min-Max Scaling)**: Scales the data to a fixed range, usually 0 to 1. Formula: \\(X' = \\frac{X - X_{min}}{X_{max} - X_{min}}\\).                                                            |\n",
    "|                          | - **Standardization (Z-score Scaling)**: Scales the data so that it has a mean of 0 and a standard deviation of 1. Formula: \\(X' = \\frac{X - \\mu}{\\sigma}\\).                                               |\n",
    "|                          | - **Robust Scaling**: Uses median and interquartile range to scale data, making it robust to outliers. Formula: \\(X' = \\frac{X - \\text{median}}{IQR}\\).                                                    |\n",
    "|                          | - **MaxAbs Scaling**: Scales each feature by its maximum absolute value. Formula: \\(X' = \\frac{X}{|X_{max}|}\\).                                                                                           |\n",
    "| **Importance**           | - Prevents features with larger ranges from dominating those with smaller ranges.                                                                                       |\n",
    "|                          | - Speeds up the convergence of gradient-based optimization algorithms.                                                                                                  |\n",
    "|                          | - Improves the accuracy and efficiency of distance-based algorithms like K-Nearest Neighbors (KNN) and Support Vector Machines (SVM).                                                                         |\n",
    "| **Scikit-learn Tools**   | - `StandardScaler`: Standardizes features by removing the mean and scaling to unit variance.                                                                             |\n",
    "|                          | - `MinMaxScaler`: Transforms features by scaling each feature to a given range.                                                                                         |\n",
    "|                          | - `RobustScaler`: Scales features using statistics that are robust to outliers.                                                                                         |\n",
    "|                          | - `MaxAbsScaler`: Scales each feature by its maximum absolute value.                                                                                                    |\n",
    "| **Example Usage**        | ```python                                                                                                                                                               |\n",
    "|                          | from sklearn.preprocessing import StandardScaler, MinMaxScaler                                                                                                          |\n",
    "|                          | import numpy as np                                                                                                                                                      |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | data = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])                                                                                                                      |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | # Standardization                                                                                                                                                       |\n",
    "|                          | scaler = StandardScaler()                                                                                                                                               |\n",
    "|                          | standardized_data = scaler.fit_transform(data)                                                                                                                           |\n",
    "|                          | print(\"Standardized Data:\\n\", standardized_data)                                                                                                                         |\n",
    "|                          |                                                                                                                                                                         |\n",
    "|                          | # Normalization                                                                                                                                                         |\n",
    "|                          | min_max_scaler = MinMaxScaler()                                                                                                                                         |\n",
    "|                          | normalized_data = min_max_scaler.fit_transform(data)                                                                                                                     |\n",
    "|                          | print(\"Normalized Data:\\n\", normalized_data)                                                                                                                             |\n",
    "|                          | ```                                                                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AxjSUXFQqo-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 154
    },
    "colab_type": "code",
    "id": "DWPET8ZdlMnu",
    "outputId": "dea86927-5124-4e2a-e974-2804df9a913c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
      " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
      " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
      " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
      " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
      " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
      " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
      " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "sTXykB_QlRjE",
    "outputId": "b68f0cfc-d07c-48cb-80d0-6800028c41f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
      " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_preprocessing_tools.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
